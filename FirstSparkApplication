#Importing Packages
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, IntegerType, StringType, StructField
import pyspark.sql.functions as func

#creating the SparkSession
spark = SparkSession.builder.appName("FirstApp").getOrCreate()

#Defining schema for your DataFrame
myschema = StructType([\
                       StructField("userID", IntegerType(), True),
                       StructField("name", StringType(), True),
                       StructField("age",IntegerType(), True),
                       StructField("friends",IntegerType(), True),
                        ])

#Creating DataFrame on a CSV file #path is fine since the CSV is in the same folder as the script.  #No Header on the File
people = spark.read.format("csv")\
    .schema(myschema)\
    .option("path","fakefriends.csv")\
    .load()

#Performing all thetransformations
output = people.select(people.userID,people.name\
                       ,people.age,people.friends)\
         .where(people.age < 30).withColumn('insert_ts', func.current_timestamp())\
         .orderBy(people.userID)

#taking the count of o/p DataFrame
output.count()

#Creating a Temp View
output.createOrReplaceTempView("peoples")

#Running a simple Spark SQL query
spark.sql("select name,age,friends,insert_ts from peoples").show()
